max_steps: 1000
epoch_len: 10
num_envs: 1
num_eval_envs: 1
seed: 0
her_params: 
  fut: 0.8
  act: 0
  ach: 0
  beh: 0
optimize_every: 2
grad_norm_clipping: -1
grad_value_clipping: -1
policy_opt_noise: 0
# update
num_eval_epochs: 8
# rl
gamma: 0.98
n_step_returns: 1
# buffer
replay_size: 2500
# update
batch_size: 10
actor_lr: !!float 1e-3
critic_lr: !!float 1e-3
target_network_update_freq: 1
target_network_update_frac: 0.05
# network
layers: [512, 512, 512]
actor_weight_decay: 0
critic_weight_decay: 0
device: 'cuda'
clip_target_range: [-50, 0]
action_l2_regularization: !!float 1e-2
# explore
warm_up: 50
eexplore: 0.2
initial_explore: 10
future_warm_up: 25
varied_action_noise: False
action_noise: 0.1
# reward
sparse_reward_shaping: False
slot_based_state: False  # CHECK
# env
max_action: 1
action_dim: 8
state_dim: 26
goal_dim: 3
num_goals: 1
max_env_steps: 50
never_done: True
env_params:
  num_envs: 1
  max_action: 1
  action_dim: 8
  state_dim: 26
  goal_dim: 3
  num_goals: 1
  max_env_steps: 50 
# wandb
wandb: False